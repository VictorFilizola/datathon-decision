{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740da12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data merging process...\n",
      "-> Loading raw data files...\n",
      "-> Flattening JSON data into tables...\n",
      "-> Merging prospects and vagas data...\n",
      "-> Saving merged data to ../data/processed/prospects_vagas_merged.json\n",
      "\n",
      "Merge complete!\n",
      "Total applications processed: 53759\n",
      "First 5 rows of the merged data:\n",
      "  vaga_id             prospect_nome prospect_codigo  \\\n",
      "0    4530               José Vieira           25632   \n",
      "1    4530  Srta. Isabela Cavalcante           25529   \n",
      "2    4531     Sra. Yasmin Fernandes           25364   \n",
      "3    4531            Alexia Barbosa           25360   \n",
      "4    4533            Arthur Almeida           26338   \n",
      "\n",
      "            situacao_candidado data_candidatura ultima_atualizacao  \\\n",
      "0  Encaminhado ao Requisitante       25-03-2021         25-03-2021   \n",
      "1  Encaminhado ao Requisitante       22-03-2021         23-03-2021   \n",
      "2     Contratado pela Decision       17-03-2021         12-04-2021   \n",
      "3  Encaminhado ao Requisitante       17-03-2021         17-03-2021   \n",
      "4     Contratado pela Decision       29-04-2021         18-05-2021   \n",
      "\n",
      "                                          comentario         recrutador  \\\n",
      "0               Encaminhado para  - PJ R$ 72,00/hora  Ana Lívia Moreira   \n",
      "1  encaminhado para  - R$ 6.000,00 – CLT Full , n...  Ana Lívia Moreira   \n",
      "2                         Data de Inicio: 12/04/2021   Juliana Cassiano   \n",
      "3                                                      Juliana Cassiano   \n",
      "4                                                         Stella Vieira   \n",
      "\n",
      "  data_requicisao limite_esperado_para_contratacao  ...  \\\n",
      "0      10-03-2021                       00-00-0000  ...   \n",
      "1      10-03-2021                       00-00-0000  ...   \n",
      "2      10-03-2021                       00-00-0000  ...   \n",
      "3      10-03-2021                       00-00-0000  ...   \n",
      "4      11-03-2021                       01-01-1970  ...   \n",
      "\n",
      "                          areas_atuacao  \\\n",
      "0     TI - Desenvolvimento/Programação-   \n",
      "1     TI - Desenvolvimento/Programação-   \n",
      "2  Gestão e Alocação de Recursos de TI-   \n",
      "3  Gestão e Alocação de Recursos de TI-   \n",
      "4  Gestão e Alocação de Recursos de TI-   \n",
      "\n",
      "                               principais_atividades  \\\n",
      "0  - Experiência comprovada em projetos de control-M   \n",
      "1  - Experiência comprovada em projetos de control-M   \n",
      "2  Key skills required for the job are:\\n\\nPeople...   \n",
      "3  Key skills required for the job are:\\n\\nPeople...   \n",
      "4  Arquiteto\\n\\nFoco na área e automação.\\n\\nRequ...   \n",
      "\n",
      "              competencia_tecnicas_e_comportamentais  \\\n",
      "0  - Experiência comprovada em projetos de control-M   \n",
      "1  - Experiência comprovada em projetos de control-M   \n",
      "2  O recurso Peoplesoft tem como responsabilidade...   \n",
      "3  O recurso Peoplesoft tem como responsabilidade...   \n",
      "4  Arquiteto\\n\\nFoco na área e automação.\\n\\nRequ...   \n",
      "\n",
      "                                  demais_observacoes viagens_requeridas  \\\n",
      "0  Contratação PJ Projeto pontual de 2 a 3 meses ...                      \n",
      "1  Contratação PJ Projeto pontual de 2 a 3 meses ...                      \n",
      "2      Remoto DEPOIS PRESENCIAL, TEMPO INDETERMINADO                      \n",
      "3      Remoto DEPOIS PRESENCIAL, TEMPO INDETERMINADO                      \n",
      "4  Atuação somente em horário comercial. Tempo in...                      \n",
      "\n",
      "  equipamentos_necessarios data_inicial data_final  \\\n",
      "0                 Nenhum -          NaN        NaN   \n",
      "1                 Nenhum -          NaN        NaN   \n",
      "2        Notebook padrão -          NaN        NaN   \n",
      "3        Notebook padrão -          NaN        NaN   \n",
      "4                      NaN          NaN        NaN   \n",
      "\n",
      "  habilidades_comportamentais_necessarias nome_substituto  \n",
      "0                                     NaN             NaN  \n",
      "1                                     NaN             NaN  \n",
      "2                                     NaN             NaN  \n",
      "3                                     NaN             NaN  \n",
      "4                              Telefonica             NaN  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "PROSPECTS_PATH = \"../data/raw/prospects.json\"\n",
    "VAGAS_PATH = \"../data/raw/vagas.json\"\n",
    "OUTPUT_PATH = \"../data/processed/prospects_vagas_merged.json\"\n",
    "\n",
    "def flatten_prospects(prospects_data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flattens the nested prospects.json data into a pandas DataFrame.\n",
    "    Each row will represent a single prospect application.\n",
    "\n",
    "    Args:\n",
    "        prospects_data: The loaded dictionary from prospects.json.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with flattened prospect data.\n",
    "    \"\"\"\n",
    "    prospects_list = []\n",
    "    # The keys of the dictionary are the vacancy IDs\n",
    "    for vaga_id, vaga_info in prospects_data.items():\n",
    "        # Iterate through the list of prospects for each vacancy\n",
    "        for prospect in vaga_info.get(\"prospects\", []):\n",
    "            # Create a dictionary for the current prospect\n",
    "            prospect_record = {\n",
    "                \"vaga_id\": vaga_id,\n",
    "                \"prospect_nome\": prospect.get(\"nome\"),\n",
    "                \"prospect_codigo\": prospect.get(\"codigo\"),\n",
    "                \"situacao_candidado\": prospect.get(\"situacao_candidado\"),\n",
    "                \"data_candidatura\": prospect.get(\"data_candidatura\"),\n",
    "                \"ultima_atualizacao\": prospect.get(\"ultima_atualizacao\"),\n",
    "                \"comentario\": prospect.get(\"comentario\"),\n",
    "                \"recrutador\": prospect.get(\"recrutador\")\n",
    "            }\n",
    "            prospects_list.append(prospect_record)\n",
    "    \n",
    "    return pd.DataFrame(prospects_list)\n",
    "\n",
    "def flatten_vagas(vagas_data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flattens the vagas.json data into a pandas DataFrame.\n",
    "    It combines the 'informacoes_basicas' and 'perfil_vaga' into a single record.\n",
    "\n",
    "    Args:\n",
    "        vagas_data: The loaded dictionary from vagas.json.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with flattened vacancy data.\n",
    "    \"\"\"\n",
    "    vagas_list = []\n",
    "    # The keys of the dictionary are the vacancy IDs\n",
    "    for vaga_id, vaga_details in vagas_data.items():\n",
    "        # Combine the two nested dictionaries into one\n",
    "        # This makes it easier to access all vacancy info\n",
    "        record = {\n",
    "            \"vaga_id\": vaga_id,\n",
    "            **vaga_details.get(\"informacoes_basicas\", {}),\n",
    "            **vaga_details.get(\"perfil_vaga\", {})\n",
    "        }\n",
    "        vagas_list.append(record)\n",
    "        \n",
    "    return pd.DataFrame(vagas_list)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the data preprocessing and merging pipeline.\n",
    "    \"\"\"\n",
    "    print(\"Starting data merging process...\")\n",
    "\n",
    "    # Create the processed data directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    # 1. Load the raw JSON files\n",
    "    print(\"-> Loading raw data files...\")\n",
    "    with open(PROSPECTS_PATH, 'r', encoding='utf-8') as f:\n",
    "        prospects_data = json.load(f)\n",
    "    \n",
    "    with open(VAGAS_PATH, 'r', encoding='utf-8') as f:\n",
    "        vagas_data = json.load(f)\n",
    "\n",
    "    # 2. Flatten the JSON data into DataFrames\n",
    "    print(\"-> Flattening JSON data into tables...\")\n",
    "    prospects_df = flatten_prospects(prospects_data)\n",
    "    vagas_df = flatten_vagas(vagas_data)\n",
    "\n",
    "    # 3. Merge the two DataFrames on the 'vaga_id'\n",
    "    print(\"-> Merging prospects and vagas data...\")\n",
    "    merged_df = pd.merge(prospects_df, vagas_df, on=\"vaga_id\", how=\"left\")\n",
    "\n",
    "    # 4. Save the result to a JSON file for the next step\n",
    "    print(f\"-> Saving merged data to {OUTPUT_PATH}\")\n",
    "    \n",
    "    # --- FIX ---\n",
    "    # Use to_json with orient='records' to create a list of JSON objects.\n",
    "    # This is a clean and standard format.\n",
    "    merged_df.to_json(OUTPUT_PATH, orient='records', indent=4, force_ascii=False)\n",
    "    # --- END FIX ---\n",
    "\n",
    "    print(\"\\nMerge complete!\")\n",
    "    print(f\"Total applications processed: {len(merged_df)}\")\n",
    "    print(\"First 5 rows of the merged data:\")\n",
    "    print(merged_df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d0bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting applicant filtering process...\n",
      "-> Loading merged data from ../data/processed/prospects_vagas_merged.json...\n",
      "-> Found 29405 unique active candidates.\n",
      "-> Loading all applicants from ../data/raw/applicants.json...\n",
      "-> Filtering applicants...\n",
      "-> Found 23463 matching applicants to process.\n",
      "-> Saving filtered applicants to ../data/processed/applicants_for_processing.json...\n",
      "\n",
      "Filtering process complete!\n",
      "The file '../data/processed/applicants_for_processing.json' is now ready for your LLM processing.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define file paths relative to the project root\n",
    "MERGED_DATA_PATH = \"../data/processed/prospects_vagas_merged.json\"\n",
    "ALL_APPLICANTS_PATH = \"../data/raw/applicants.json\" \n",
    "OUTPUT_PATH = \"../data/processed/applicants_for_processing.json\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Filters the main applicants list to include only those who appear\n",
    "    in the prospects data, preparing them for LLM processing.\n",
    "    \"\"\"\n",
    "    print(\"Starting applicant filtering process...\")\n",
    "\n",
    "    # Create the processed data directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    # 1. Load the merged prospects/vagas data to get active candidate IDs\n",
    "    print(f\"-> Loading merged data from {MERGED_DATA_PATH}...\")\n",
    "    with open(MERGED_DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        merged_data = json.load(f)\n",
    "\n",
    "    # Extract the unique set of candidate codes from the prospects data\n",
    "    # The 'prospect_codigo' is a string, so we keep it that way.\n",
    "    active_candidate_ids = {str(record['prospect_codigo']) for record in merged_data}\n",
    "    print(f\"-> Found {len(active_candidate_ids)} unique active candidates.\")\n",
    "\n",
    "    # 2. Load the main applicants data\n",
    "    print(f\"-> Loading all applicants from {ALL_APPLICANTS_PATH}...\")\n",
    "    with open(ALL_APPLICANTS_PATH, 'r', encoding='utf-8') as f:\n",
    "        # applicants.json is a dictionary where keys are the applicant IDs\n",
    "        all_applicants_data = json.load(f)\n",
    "\n",
    "    # 3. Filter the applicants\n",
    "    print(\"-> Filtering applicants...\")\n",
    "    filtered_applicants = {}\n",
    "    for applicant_id, applicant_details in all_applicants_data.items():\n",
    "        # Check if the applicant's ID is in our set of active IDs\n",
    "        if applicant_id in active_candidate_ids:\n",
    "            filtered_applicants[applicant_id] = applicant_details\n",
    "    \n",
    "    print(f\"-> Found {len(filtered_applicants)} matching applicants to process.\")\n",
    "\n",
    "    # 4. Save the filtered list to a new JSON file\n",
    "    print(f\"-> Saving filtered applicants to {OUTPUT_PATH}...\")\n",
    "    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(filtered_applicants, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(\"\\nFiltering process complete!\")\n",
    "    print(f\"The file '{OUTPUT_PATH}' is now ready for your LLM processing.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
